{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c22a1b-95d2-489b-8c77-398f108622d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome! Please select a store to analyze:\n",
      "1. Amazon\n",
      "2. Best Buy\n",
      "3. Nike\n",
      "4. K Mart\n",
      "5. Target\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number of the store you want to analyze (1-5):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing transactions for Nike:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter minimum support (1-100):  55\n",
      "Enter minimum confidence (1-100):  70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Executing algorithms...\n",
      "\n",
      "Brute Force Execution Time: 0.0012 seconds\n",
      "Apriori Execution Time: 0.0098 seconds\n",
      "\n",
      "The faster algorithm was: Brute Force with a duration of 0.0012 seconds\n",
      "\n",
      "Results Comparison:\n",
      "Brute Force: 8 frequent itemsets, 6 rules\n",
      "Apriori: 8 frequent itemsets, 6 rules\n",
      "Same number of frequent itemsets: True\n",
      "Same number of rules: True\n",
      "\n",
      "Brute Force Association Rules:\n",
      "Rule 1: {'Socks'} -> {'Sweatshirts'} (Confidence: 0.92, Support: 0.60)\n",
      "Rule 2: {'Sweatshirts'} -> {'Socks'} (Confidence: 0.92, Support: 0.60)\n",
      "Rule 3: {'Sweatshirts'} -> {'Running Shoe'} (Confidence: 0.85, Support: 0.55)\n",
      "Rule 4: {'Running Shoe'} -> {'Sweatshirts'} (Confidence: 0.79, Support: 0.55)\n",
      "Rule 5: {'Socks'} -> {'Running Shoe'} (Confidence: 0.85, Support: 0.55)\n",
      "Rule 6: {'Running Shoe'} -> {'Socks'} (Confidence: 0.79, Support: 0.55)\n",
      "\n",
      "Apriori Association Rules:\n",
      "Rule 1: {'Socks'} -> {'Running Shoe'} (Confidence: 0.85, Support: 0.55)\n",
      "Rule 2: {'Running Shoe'} -> {'Socks'} (Confidence: 0.79, Support: 0.55)\n",
      "Rule 3: {'Sweatshirts'} -> {'Running Shoe'} (Confidence: 0.85, Support: 0.55)\n",
      "Rule 4: {'Running Shoe'} -> {'Sweatshirts'} (Confidence: 0.79, Support: 0.55)\n",
      "Rule 5: {'Socks'} -> {'Sweatshirts'} (Confidence: 0.92, Support: 0.60)\n",
      "Rule 6: {'Sweatshirts'} -> {'Socks'} (Confidence: 0.92, Support: 0.60)\n",
      "\n",
      "Item Counts:\n",
      "Socks: Count = 13, Support = 0.65 (Meets support threshold)\n",
      "Sweatshirts: Count = 13, Support = 0.65 (Meets support threshold)\n",
      "Modern Pants: Count = 10, Support = 0.50 (Does not meet support threshold)\n",
      "Running Shoe: Count = 14, Support = 0.70 (Meets support threshold)\n",
      "Soccer Shoe: Count = 6, Support = 0.30 (Does not meet support threshold)\n",
      "Rash Guard: Count = 12, Support = 0.60 (Meets support threshold)\n",
      "Tech Pants: Count = 9, Support = 0.45 (Does not meet support threshold)\n",
      "Hoodies: Count = 8, Support = 0.40 (Does not meet support threshold)\n",
      "Swimming Shirt: Count = 11, Support = 0.55 (Meets support threshold)\n",
      "Dry Fit V-Nick: Count = 10, Support = 0.50 (Does not meet support threshold)\n",
      "\n",
      "Would you like to analyze another store? (y/n)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import time\n",
    "from mlxtend.frequent_patterns import apriori as apriori_lib\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Function to read transactions from a CSV file\n",
    "def read_transactions_from_csv(file_path):\n",
    "    data_frame = pd.read_csv(file_path, header=None)\n",
    "    return [set(str(item) for item in transaction if pd.notna(item)) for transaction in data_frame.values.tolist()]\n",
    "\n",
    "# Function to ensure valid float input for support and confidence\n",
    "def get_valid_float(prompt, min_value, max_value):\n",
    "    while True:\n",
    "        try:\n",
    "            user_input = float(input(prompt))\n",
    "            if min_value <= user_input <= max_value:\n",
    "                return user_input / 100  # Convert percentage to decimal\n",
    "            else:\n",
    "                print(f\"Please provide a value between {min_value} and {max_value}.\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a valid number.\")\n",
    "\n",
    "# Function to ensure valid integer input for store selection\n",
    "def get_valid_int(prompt, min_value, max_value):\n",
    "    while True:\n",
    "        try:\n",
    "            user_input = int(input(prompt))\n",
    "            if min_value <= user_input <= max_value:\n",
    "                return user_input\n",
    "            else:\n",
    "                print(f\"Please provide a number between {min_value} and {max_value}.\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a valid integer.\")\n",
    "\n",
    "# Dictionary of stores and their corresponding transaction files\n",
    "store_files = {\n",
    "    \"Amazon\": \"amazon_transactions.csv\",\n",
    "    \"Best Buy\": \"bestbuy_transactions.csv\",\n",
    "    \"Nike\": \"nike_transactions.csv\",\n",
    "    \"K Mart\": \"k_mart_transactions.csv\",\n",
    "    \"Target\": \"target_transactions.csv\"\n",
    "}\n",
    "\n",
    "# Brute force method for finding frequent itemsets and generating rules\n",
    "def brute_force_algorithm(transactions, min_support, min_confidence):\n",
    "    def count_itemsets(itemsets):\n",
    "        counts = defaultdict(int)\n",
    "        for transaction in transactions:\n",
    "            for itemset in itemsets:\n",
    "                if set(itemset).issubset(transaction):\n",
    "                    counts[itemset] += 1\n",
    "        return counts\n",
    "\n",
    "    unique_items = set(item for transaction in transactions for item in transaction)\n",
    "    total_transactions = len(transactions)\n",
    "    frequent_itemsets = {}\n",
    "    k = 1\n",
    "\n",
    "    while True:\n",
    "        itemsets = list(itertools.combinations(unique_items, k))\n",
    "        item_counts = count_itemsets(itemsets)\n",
    "        frequent_items = {frozenset(item): count / total_transactions for item, count in item_counts.items() if count / total_transactions >= min_support}\n",
    "        if not frequent_items:\n",
    "            break\n",
    "        frequent_itemsets[k] = frequent_items\n",
    "        k += 1\n",
    "\n",
    "    generated_rules = []\n",
    "    for k in range(2, len(frequent_itemsets) + 1):\n",
    "        for itemset in frequent_itemsets[k]:\n",
    "            for i in range(1, k):\n",
    "                for antecedent in itertools.combinations(itemset, i):\n",
    "                    antecedent_set = frozenset(antecedent)\n",
    "                    consequent_set = frozenset(itemset) - antecedent_set\n",
    "                    if antecedent_set in frequent_itemsets[len(antecedent_set)]:\n",
    "                        support = frequent_itemsets[k][itemset]\n",
    "                        confidence = support / frequent_itemsets[len(antecedent_set)][antecedent_set]\n",
    "                        if confidence >= min_confidence:\n",
    "                            generated_rules.append((antecedent_set, consequent_set, confidence, support))\n",
    "\n",
    "    return frequent_itemsets, generated_rules\n",
    "\n",
    "# Apriori algorithm using the mlxtend library\n",
    "def apriori_algorithm(transactions, min_support, min_confidence):\n",
    "    encoder = TransactionEncoder()\n",
    "    encoded_array = encoder.fit(transactions).transform(transactions)\n",
    "    df = pd.DataFrame(encoded_array, columns=encoder.columns_)\n",
    "    frequent_itemsets = apriori_lib(df, min_support=min_support, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
    "    return frequent_itemsets, rules\n",
    "\n",
    "# Function to compare results from both algorithms\n",
    "def compare_algorithms(brute_force_results, apriori_results):\n",
    "    bf_itemsets, bf_rules = brute_force_results\n",
    "    ap_itemsets, ap_rules = apriori_results\n",
    "\n",
    "    print(\"\\nResults Comparison:\")\n",
    "    print(f\"Brute Force: {sum(len(itemsets) for itemsets in bf_itemsets.values())} frequent itemsets, {len(bf_rules)} rules\")\n",
    "    print(f\"Apriori: {len(ap_itemsets)} frequent itemsets, {len(ap_rules)} rules\")\n",
    "\n",
    "    # Check if both methods yield the same results\n",
    "    same_itemsets_count = (sum(len(itemsets) for itemsets in bf_itemsets.values()) == len(ap_itemsets))\n",
    "    same_rules_count = len(bf_rules) == len(ap_rules)\n",
    "    print(f\"Same number of frequent itemsets: {same_itemsets_count}\")\n",
    "    print(f\"Same number of rules: {same_rules_count}\")\n",
    "\n",
    "# Function to display the generated association rules\n",
    "def show_rules(rules, algorithm_name):\n",
    "    print(f\"\\n{algorithm_name} Association Rules:\")\n",
    "    if isinstance(rules, list):  # For brute force results\n",
    "        for index, (antecedent, consequent, confidence, support) in enumerate(rules, 1):\n",
    "            print(f\"Rule {index}: {set(antecedent)} -> {set(consequent)} \"\n",
    "                  f\"(Confidence: {confidence:.2f}, Support: {support:.2f})\")\n",
    "    elif isinstance(rules, pd.DataFrame):  # For library results (Apriori)\n",
    "        for index, rule in rules.iterrows():\n",
    "            antecedents = list(rule['antecedents'])\n",
    "            consequents = list(rule['consequents'])\n",
    "            print(f\"Rule {index + 1}: {set(antecedents)} -> {set(consequents)} \"\n",
    "                  f\"(Confidence: {rule['confidence']:.2f}, Support: {rule['support']:.2f})\")\n",
    "    else:\n",
    "        print(\"No rules found or unsupported rule format.\")\n",
    "\n",
    "# Main loop for user interaction\n",
    "while True:\n",
    "    print(\"\\nWelcome! Please select a store to analyze:\")\n",
    "    for idx, store in enumerate(store_files.keys(), 1):\n",
    "        print(f\"{idx}. {store}\")\n",
    "    \n",
    "    # Store selection using integer input validation\n",
    "    selected_store = get_valid_int(\"Enter the number of the store you want to analyze (1-5): \", 1, 5)\n",
    "    store_name = list(store_files.keys())[selected_store - 1]\n",
    "    \n",
    "    try:\n",
    "        # Load transactions from the selected store's CSV file\n",
    "        transactions = read_transactions_from_csv(store_files[store_name])\n",
    "        \n",
    "        print(f\"\\nAnalyzing transactions for {store_name}:\")\n",
    "        min_support = get_valid_float(\"Enter minimum support (1-100): \", 1, 100)\n",
    "        min_confidence = get_valid_float(\"Enter minimum confidence (1-100): \", 1, 100)\n",
    "        \n",
    "        print(\"\\nExecuting algorithms...\")\n",
    "        \n",
    "        # Run brute force algorithm\n",
    "        start_time = time.time()\n",
    "        bf_itemsets, bf_rules = brute_force_algorithm(transactions, min_support, min_confidence)\n",
    "        bf_duration = time.time() - start_time\n",
    "        \n",
    "        # Run Apriori algorithm\n",
    "        start_time = time.time()\n",
    "        ap_itemsets, ap_rules = apriori_algorithm(transactions, min_support, min_confidence)\n",
    "        ap_duration = time.time() - start_time\n",
    "        \n",
    "        print(f\"\\nBrute Force Execution Time: {bf_duration:.4f} seconds\")\n",
    "        print(f\"Apriori Execution Time: {ap_duration:.4f} seconds\")\n",
    "        \n",
    "        # Determine the faster algorithm\n",
    "        faster_algorithm = min((\"Brute Force\", bf_duration), (\"Apriori\", ap_duration), key=lambda x: x[1])\n",
    "        print(f\"\\nThe faster algorithm was: {faster_algorithm[0]} with a duration of {faster_algorithm[1]:.4f} seconds\")\n",
    "        \n",
    "        # Compare results and display rules\n",
    "        compare_algorithms((bf_itemsets, bf_rules), (ap_itemsets, ap_rules))\n",
    "        show_rules(bf_rules, \"Brute Force\")\n",
    "        show_rules(ap_rules, \"Apriori\")\n",
    "        \n",
    "        # Display item counts and support\n",
    "        print(\"\\nItem Counts:\")\n",
    "        item_count_dict = defaultdict(int)\n",
    "        for transaction in transactions:\n",
    "            for item in transaction:\n",
    "                item_count_dict[item] += 1\n",
    "        \n",
    "        for item, count in item_count_dict.items():\n",
    "            support_value = count / len(transactions)\n",
    "            meets_threshold = \"Meets\" if support_value >= min_support else \"Does not meet\"\n",
    "            print(f\"{item}: Count = {count}, Support = {support_value:.2f} ({meets_threshold} support threshold)\")\n",
    "\n",
    "    except Exception as error:\n",
    "        print(f\"An error occurred: {str(error)}\")\n",
    "        print(\"Please verify your input data and try again.\")\n",
    "    \n",
    "    # Ask user if they want to analyze another store\n",
    "    print(\"\\nWould you like to analyze another store? (y/n)\")\n",
    "    if input().lower() != 'y':\n",
    "        break\n",
    "\n",
    "print(\"Thank you for using the program!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3ca6d1-fdbd-4d0b-acf3-e89152bc684c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
